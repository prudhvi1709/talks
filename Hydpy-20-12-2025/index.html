<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <title>LLM-Powered Data Engineering: Automating Schemas, Ingestion and Quality</title>
  <meta name="viewport" content="width=device-width, initial-scale=1.0">

  <!-- Reveal.js -->
  <link rel="stylesheet" href="https://unpkg.com/reveal.js/dist/reveal.css">
  <link rel="stylesheet" href="https://unpkg.com/reveal.js/dist/theme/white.css">

  <!-- Custom minimal styling -->
  <style>
    body {
      background: #ffffff;
    }
    .reveal h1, .reveal h2, .reveal h3 {
      letter-spacing: -0.02em;
      color: #222;
    }
    .reveal h1 {
      font-size: 1.6em;
    }
    .reveal h2 {
      font-size: 1.2em;
    }
    .reveal p, .reveal li {
      font-size: 1.0em;
      color: #333;
    }
    .muted {
      color: #666;
      font-size: 0.8em;
    }
    .accent {
      color: #2563eb;
    }
  </style>
</head>

<body>
<div class="reveal">
<div class="slides">

<!-- Slide 1 -->
<section>
  <h1>LLM-Powered Data Engineering</h1>
  <p class="accent">Automating Schemas, Ingestion and Quality</p>
  <p class="muted">Prudhvi Krovvidi · Hyderabad Python Meetup</p>
  <div style="text-align: center; margin-top: 1em;">
    <img src="assets/talk-qr.png" alt="Talk QR" style="max-width: 300px; height: auto; border-radius: 10px; box-shadow: 0 4px 12px rgba(0,0,0,0.1);">
  </div>

  <aside class="notes">
    Hi, I'm Prudhvi.
    This talk is not a product pitch or a sales demo.
    
    What I want to share today is an open-source exploration of how LLMs can live inside real Python data pipelines, not outside them.
    We'll also do a live demo — not screenshots — so you can see this working end to end.
  </aside>
</section>

<!-- Slide 1.5 -->
<section>
  <h2>Links</h2>
  <ul>
    <li><a href="https://www.youtube.com/watch?v=nclyldi9b0Q" target="_blank">Watch the talk on YouTube</a></li>
    <li><a href="transcript-hydpy.md" target="_blank">Read the transcript</a></li>
  </ul>
</section>

<!-- Slide 2 -->
<section>
    <h2>Why LLMs in data engineering?</h2>
    <ul>
      <li>Systems are growing</li>
      <li>Change is constant</li>
      <li>Humans translate intent</li>
    </ul>
  
    <aside class="notes">
      Before jumping into schemas, zoom out.
      Modern data systems are large and constantly evolving.
      A lot of engineering effort goes into translating intent into structure and rules.
      That translation layer is where LLMs are actually useful.
    </aside>
</section>
  
<!-- Slide 3 -->
<section>
  <h2>Data breaks late.</h2>
  <h2 class="accent">Schemas drift silently.</h2>

  <aside class="notes">
    Most of us here work with Python ETL in some form.
    Pipelines usually don't fail immediately when something changes — they fail late.
    
    Schema changes rarely come with alarms.
    A new field appears, a type subtly changes, a value becomes nullable — and nothing breaks right away.
    
    The problem shows up much later, when dbt tests fail, dashboards break, or downstream consumers start seeing bad data.
    
    By then, we're debugging history instead of preventing the issue.
  </aside>
</section>

<!-- Slide 4 -->
<section>
  <h2>Where we spend human time</h2>
  <ul>
    <li>Writing schemas</li>
    <li>Updating dbt tests</li>
    <li>Debugging mismatches</li>
  </ul>

  <aside class="notes">
    If you think about it, a lot of our time goes into:
    writing schema files,
    updating dbt tests,
    and debugging mismatches between Python and SQL.
    
    This is not creative work — it's translation work.
    Humans are repeatedly converting intent into checks.
  </aside>
</section>

<!-- Slide 5 -->
<section>
  <h2>LLMs are good at</h2>
  <h2 class="accent">reasoning, understanding context, not guessing</h2>

  <aside class="notes">
    When people hear "LLMs", they often think prompt-to-output magic.
    That's not what this is about.
    
    LLMs are actually very good at understanding structure, explaining change, and reasoning about compatibility.
    That maps extremely well to schema work.
  </aside>
</section>

<!-- Slide 6 -->
<section>
  <h2>Schemas are</h2>
  <h1 class="accent">living artifacts</h1>

  <aside class="notes">
    Schemas are not static contracts that you write once and forget.
    They evolve as data and business logic evolve.
    
    Humans already reason about schemas all the time:
    Is this breaking?
    Is this safe to deploy?
    
    SchemaForge is about automating that reasoning loop, not replacing humans.
  </aside>
</section>

<!-- Slide 7 -->
<section>
  <h2>What is <a href="https://prudhvi1709.github.io/schemaforge/" target="_blank">SchemaForge</a>?</h2>
  <ul>
    <li>Web-based schema reasoning engine</li>
    <li>Upload CSV/Excel, get dbt rules</li>
    <li>Interactive ER diagrams</li>
    <li>Chat with your data</li>
  </ul>

  <aside class="notes">
    SchemaForge is a web-based tool that runs entirely in your browser.
    
    You upload a CSV or Excel file, and it generates complete dbt projects with data quality tests.
    But here's what makes it interesting: it includes interactive ER diagrams where you can visualize relationships between tables.
    And there's a chat interface where you can ask questions about your data in natural language.
    
    The key insight: this isn't just schema inference. It's a complete workflow tool that understands your data semantically.
    Nothing here replaces Python or dbt — it augments them.
  </aside>
</section>

<!-- Slide 8 -->
<section>
  <h2>The data flow</h2>
  <p><strong>Raw Data → Schema Inference → Relationship Detection → dbt Rules → Validation</strong></p>

  <aside class="notes">
    Let me walk you through how this actually works in practice.
    
    Step 1: Raw Data - You start with CSV or Excel files. The kind of data you already have.
    
    Step 2: Schema Inference - The LLM analyzes structure, types, and semantics. Not just "this is a string" but "this is an email address, it's PII."
    
    Step 3: Relationship Detection - It infers foreign keys, identifies primary keys, understands how tables connect. This is where it goes beyond simple type detection.
    
    Step 4: dbt Rules Generation - It translates that understanding into executable dbt tests. Uniqueness checks, not-null constraints, relationship tests.
    
    Step 5: Validation - You review and deploy. The LLM suggests, you decide.
    
    The key insight: this isn't just automation. It's reasoning about your data structure, then codifying that reasoning into tests.
    
    This flow fits naturally between your ETL and your data quality checks. It doesn't replace either, it connects them.
  </aside>
</section>

<!-- Slide 9 -->
<section>
  <h2>Demo walkthrough</h2>
  <ol>
    <li>Upload CSV/Excel file</li>
    <li>Watch real-time schema inference</li>
    <li>Explore interactive ER diagram</li>
    <li>Chat: "Find potential data quality issues"</li>
    <li>Export complete dbt project</li>
  </ol>

  <aside class="notes">
    I'll switch to the live demo now. Watch for five specific things:
    
    First, I'll upload a CSV file. Notice it processes multi-sheet Excel files too.
    
    Second, watch the schema inference happen in real-time. You'll see the LLM response streaming in, not waiting for completion. This is important for large files.
    
    Third, the ER diagram. I can drag tables around, see relationships, understand foreign keys visually. This is built with GoJS and it's fully interactive.
    
    Fourth, the chat interface. I'll ask it "Find potential data quality issues in this dataset." Watch how it analyzes the data and suggests specific dbt tests.
    
    Fifth, I'll export the complete dbt project. This isn't just YAML. It's a full project with setup scripts, profiles, models, and tests. You can run "bash setup_dbt.sh" and have a working dbt environment in seconds.
    
    DEMO NARRATION DURING EACH STEP:
    Upload: "Here's a customer transactions file with multiple sheets."
    Schema: "Notice it's not just detecting types. It's understanding semantics. 'email' is flagged as PII automatically."
    ER Diagram: "See these relationships? It inferred that customer_id is a foreign key without being told."
    Chat: "Let me ask it a question... and watch the response stream in real-time."
    Export: "One click, and I have a production-ready dbt project with automated setup."
    
    If the demo slows down: The key insight is that this bridges the gap between raw data and production-ready data quality checks. No manual translation needed.
  </aside>
</section>

<!-- Slide 10 -->
<section>
  <h2>Real-world impact</h2>
  <ul>
    <li>Zero to dbt project in 2 minutes</li>
    <li>Automatic PII detection</li>
    <li>Visual schema exploration</li>
    <li>Natural language to SQL</li>
  </ul>

  <aside class="notes">
    Let me give you concrete examples of how this changes your workflow:
    
    Scenario 1: New data source arrives. Traditionally, you'd spend an hour writing schema definitions, another hour creating dbt tests. With SchemaForge, upload the file, get a complete dbt project in 2 minutes. Not an exaggeration. Two minutes.
    
    Scenario 2: Compliance audit asks "where's our PII?" Instead of manually reviewing every column, upload your schemas. It automatically flags email, phone, SSN, credit card patterns. Privacy by default.
    
    Scenario 3: You inherit a complex database with 50 tables. Instead of reading documentation that's probably outdated, upload the schemas and see an interactive ER diagram. Drag tables around, understand relationships visually.
    
    Scenario 4: Business asks "can we add a uniqueness check on customer_email?" Instead of writing SQL, ask the chat: "Add uniqueness test for customer_email." It generates the dbt YAML immediately.
    
    This isn't about replacing your expertise. It's about eliminating the boring translation work so you can focus on the interesting problems.
  </aside>
</section>

<!-- Slide 11 -->
<section>
  <h2>Run it anywhere</h2>
  <ul>
    <li>Browser with OpenAI API</li>
    <li>Laptop with Ollama (no internet)</li>
    <li>CI/CD with custom LLM endpoint</li>
    <li>Pre-commit hooks for validation</li>
  </ul>

  <aside class="notes">
    One of the most interesting architectural decisions: extreme flexibility in deployment.
    
    Option 1: Use it in your browser with OpenAI API. Standard approach, works great.
    
    Option 2: Run Ollama locally on your laptop. No API keys, no internet required, no data leaving your machine. Perfect for sensitive data or air-gapped environments. This is huge for enterprises with strict data policies.
    
    Option 3: Point it at your company's internal LLM endpoint. Many companies are running their own models. SchemaForge works with any OpenAI-compatible API.
    
    Option 4: Integrate into CI/CD. Generate dbt tests automatically when schemas change. Everything is deterministic and reviewable in Git.
    
    The pattern here is: you choose your deployment model based on your constraints. The tool adapts to your environment, not the other way around.
    
    This is what makes it production-ready for real companies with real compliance requirements.
  </aside>
</section>

<!-- Slide 12 -->
<section>
    <h2>What stays the same</h2>
    <ul>
      <li>Python owns ETL</li>
      <li>dbt owns execution</li>
      <li>Humans own decisions</li>
    </ul>
  
    <aside class="notes">
      Let me be clear about what this doesn't replace:
      
      Python still owns ETL logic. SchemaForge doesn't write your data pipelines.
      
      dbt still executes all checks. SchemaForge generates the rules, but dbt runs them.
      
      Humans still own decisions and accountability. The LLM suggests, you approve.
      
      SchemaForge just reduces the translation burden between intent and implementation.
      
      It's a tool, not a replacement for thinking. It's augmentation, not automation.
    </aside>
  </section>
  

<!-- Slide 14 -->
<section>
  <h2>Try it yourself</h2>
  <p class="accent">prudhvi1709.github.io/schemaforge</p>
  <p class="muted">Scan the QR · Connect · Contribute</p>
  <img src="assets/qr.png" alt="QR Code" style="max-width: 200px; height: auto; border-radius: 8px; box-shadow: 0 4px 12px rgba(0,0,0,0.1);">
  
  <aside class="notes">
    This is completely open source. MIT licensed.
    
    You can try it right now at prudhvi1709.github.io/schemaforge. No signup, no installation. Just open it and upload a CSV.
    
    The GitHub repo has the full source code. It's a great reference if you're building similar tools.
    
    Even if you don't use SchemaForge directly, the pattern is reusable: LLMs for schema reasoning, streaming for UX, client-side for privacy.
    
    Happy to take questions, especially around:
    - How this fits into existing pipelines
    - Trade-offs between local and cloud LLMs
    - Where this approach may not fit
    - Technical implementation details
    - Privacy and compliance considerations
    
    PERSONAL REMINDERS:
    Slow down.
    Pause before the demo.
    Let the demo breathe.
    Don't over-explain AI internals.
    Always anchor back to Python and dbt.
    Emphasize the real-world scenarios.
    Show enthusiasm but stay grounded.
  </aside>
</section>

</div>
</div>

<script src="https://unpkg.com/reveal.js/dist/reveal.js"></script>
<script src="https://unpkg.com/reveal.js/plugin/notes/notes.js"></script>
<script>
  Reveal.initialize({
    hash: true,
    slideNumber: true,
    transition: 'fade',
    plugins: [ RevealNotes ]
  });
</script>
</body>
</html>
